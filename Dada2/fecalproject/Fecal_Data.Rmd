---
title: "Fecal Extractions"
output: word_document
editor_options: 
  chunk_output_type: console
---
Based on vigenette
https://benjjneb.github.io/dada2/bigdata_paired.html
https://bioconductor.org/packages/devel/bioc/vignettes/dada2/inst/doc/dada2-intro.html

Install packages
```{r}
.cran_packages <- c("ggplot2", "gridExtra", "survival")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
   source("http://bioconductor.org/biocLite.R")
   biocLite(.bioc_packages[!.inst], ask = F)
}
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
source("http://bioconductor.org/biocLite.R")
biocLite("phyloseq")
```


Load Library's
```{r}
library("knitr")
library(dada2); packageVersion("dada2")
library(phangorn)
library("phyloseq")
library("gridExtra")
library("ggplot2")
library(DECIPHER)
library(phyloseqGraphTest)
library(permute)
library(lattice)
library(vegan)
library(ade4)
library(dplyr)
library(reshape2)
library(DESeq2)
library(ggplot2)
library(MASS)
```

Perform Filtering of data of Run 3
```{r}
# Set path of samples
pathF <- "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run3/forward"
pathR <- "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run3/reverse"

#Set path of filtered samples
filtpathF <- file.path(pathF, "filtered") # Filtered forward files go into the pathF/filtered/ subdirectory
filtpathR <- file.path(pathR, "filtered") # ...
fastqFs <- sort(list.files(pathF, pattern="fastq.gz"))
fastqRs <- sort(list.files(pathR, pattern="fastq.gz"))

#QC check to make sure fastq forward and reverse are the same
if(length(fastqFs) != length(fastqRs)) stop("Forward and reverse files do not match.")

#Review Quality Profiles of any file
plotQualityProfile(filtpathF[1])
plotQualityProfile(filtpathR)

# Filt and trim the data, store new files in filtered path- forward trimmed LESS than reverse
filterAndTrim(fwd=file.path(pathF, fastqFs), filt=file.path(filtpathF, fastqFs),
              rev=file.path(pathR, fastqRs), filt.rev=file.path(filtpathR, fastqRs),
              truncLen=c(240,200), maxEE=2, truncQ=11, maxN=0, rm.phix=TRUE,
              compress=TRUE, verbose=TRUE, multithread=TRUE)
```

Filter Run3
```{r}
# File parsing of filtered FastQ files
filtpathF <- "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run3/forward/filtered" 
filtpathR <- "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run3/reverse/filtered"
filtFs <- list.files(filtpathF, pattern="fastq.gz", full.names = TRUE)
filtRs <- list.files(filtpathR, pattern="fastq.gz", full.names = TRUE)

#Parse sample names
sample.namesF <- sapply(strsplit(basename(filtFs), "_"), `[`, 1) # Assumes filename = samplename_primer.fastq.gz
sample.namesR <- sapply(strsplit(basename(filtRs), "_"), `[`, 1) # Assumes filename = samplename_primer.fastq.gz
if(!identical(sample.namesF, sample.namesR)) stop("Forward and reverse files do not match.")

#Remove unneeded files
#Apply names - are the same, so apply F to both - to the filtered files
names(filtFs) <- sample.namesF
names(filtRs) <- sample.namesF

# Learn error rates
set.seed(100)
errF <- learnErrors(filtFs, nbases=1e8, multithread=TRUE)
errR <- learnErrors(filtRs, nbases=1e8, multithread=TRUE)

#Create list of names partially completed runs
sample.names.partial <- sample.namesF[86:96]

# Sample inference and merger of paired-end reads
mergers <- vector("list", length(sample.namesF))
names(mergers) <- sample.namesF
for(sam in sample.names.partial) {
  cat("Processing:", sam, "\n")
    derepF <- derepFastq(filtFs[[sam]])
    ddF <- dada(derepF, err=errF, multithread=TRUE)
    derepR <- derepFastq(filtRs[[sam]])
    ddR <- dada(derepR, err=errR, multithread=TRUE)
    merger <- mergePairs(ddF, derepF, ddR, derepR)
    mergers[[sam]] <- merger
}

#Remove large data files
rm(derepF); rm(derepR)

# Construct sequence table and write to run folder
seqtab <- makeSequenceTable(mergers)
saveRDS(seqtab, "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run3/Output/seqtab_ori_run3.rds")
```

Merge runs
```{r}
# Merge multiple runs 
st1 <- readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run1/Output/seqtab_ori_run1.rds")
st2 <- readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run2/Output/seqtab_ori_run2.rds")
st3 <- readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Run3/Output/seqtab_ori_run3.rds")
st.all <- mergeSequenceTables(st1, st2, st3)
st.all <- st3
```

Chimera Removal
```{r}
# Remove chimeras
seqtab <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE)

#Percent remaining after chimera removal - Seqtab = no chimeras, st.all = with chimeras
sum(seqtab)/sum(st.all)
```

Assign Taxonomy
```{r}
# Assign taxonomy using Silva reference
taxtab <- assignTaxonomy(seqtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/References/silva_nr_v128_train_set.fa.gz", multithread=TRUE)
taxtab <- addSpecies(taxtab, "C:/Users/sevillas2/Google Drive/My Documents/Education/George Mason University/BINF703/2018_Spring_BaranovaGillevet/Analysis/DADA2/References/silva_species_assignment_v128.fa.gz")

# Write to disk - Seqtab has all chimeras removed, whereas taxtab is annotated
saveRDS(seqtab, "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/seqtab_final_3only.rds") 
saveRDS(taxtab, "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/tax_final_3only.rds")

#Review the current top represetative groups
taxa.print <- taxtab # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)

###Clean environment###
```

Align the sequences, and fit to tree
```{r}
#load phylo objects
seqtab <- readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/seqtab_final_3only.rds")
taxtab <- readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/tax_final_3only.rds")

#Pull all the sequence data, align sequences
seqs <- getSequences(seqtab)
names(seqs) <- seqs 
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)

#Align the tree with phy data
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) 
fit = pml(treeNJ, data=phang.align)

fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
                      rearrangement = "stochastic", control = pml.control(trace = 0))
```

Create PhyloSeq Object
```{r}
#Set path of metadata of sample information
mimarks_path <- file.path("T:/DCEG/CGF/TechTransfer/Microbiome/Extraction/Optimization/Fresh Fecal Optimization_2017.08/PhyloInput.csv")
samdf <- read.csv(mimarks_path, header=TRUE)

# Verificattion - TRUE - if false check sample names - they must match
all(rownames(seqtab) %in% samdf$SampleID) ##Check that the rownames match

#Create phylo object for conversion - includes tax data and metadata
rownames(samdf) <- samdf$SampleID
samdf <- samdf[rownames(seqtab), ]
ps <- phyloseq(tax_table(taxtab),
                 sample_data(samdf),
                 otu_table(seqtab, taxa_are_rows = FALSE),
                 phy_tree(fitGTR$tree))
saveRDS(ps, "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps_3only.rds")
###Clean Environment###
```

Load Phylo Data
```{r}
#load the phylo object
ps = readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps_3only.rds")
```

Review Richness before filtering
```{r}
#Review diversity (richness)
plot_richness(ps,x="Kit",measures=c("Shannon","Simpson"), color="Kit") + theme_bw() + geom_boxplot()
plot_richness(ps,x="Type",measures=c("Shannon","Simpson"), color="Type") + theme_bw() + geom_boxplot()
plot_richness(ps,x="VialID",measures=c("Shannon","Simpson"), color="VialID") + theme_bw() + geom_boxplot()
```

PhyloSeq Filtering - Supervised
```{r}
#Determine if anything needs to be filtered
table(tax_table(ps)[, "Phylum"], exclude = NULL) 

#Remove all NA from set
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized")) 

# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
                 MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
                 FUN = function(x){sum(x > 0)})

# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                      TotalAbundance = taxa_sums(ps),
                      tax_table(ps))
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})

#Filter species foud in one one sample after reviewing above table
filterPhyla = c("Acidobacteria", "Ascomycota", "Parcubacteria", "Spirochaetae", "SR1_(Absconditabacteria)", "Tenericutes")

# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
```

PhyloSeq Filtering - Unsupervised
```{r}
#Review dataset for phylum that are under represented
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) + 
 geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) + 
 geom_point(size = 2, alpha = 0.7) + scale_x_log10() +  
 xlab("Total Abundance") + 
 ylab("Prevalence [Frac. Samples]") + 
 facet_wrap(~Phylum) + 
 theme(legend.position="none")
```

Define New thresholds
```{r}
#  Define prevalence threshold as a percentage of total samples (between 5-10)
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold #Review value
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps1)

# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```

Aggregate the data
```{r}
#Rank on Genus for set
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)

#Rank on Height of the branch
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)

#Compare the options, before/genus/height
multiPlotTitleTextSize = 8
p2tree = plot_tree(ps2, method = "treeonly",
                     ladderize = "left",
                     title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                     ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                     ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
plot(grid.arrange(nrow = 1, p2tree, p3tree, p4tree))

#Determine which is the best method
ps5 <- ps3
```

Transform data for abundances
```{r}
plot_abundance = function(physeq,title = "",
			     Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
  mphyseq = psmelt(ps5)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "Kit",y = "Abundance",
                                 color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
                position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}

#Transform data
ps6 = transform_sample_counts(ps5, function(x){x / sum(x)})

#Plot the before and after
plotBefore = plot_abundance(ps5,"")
plotAfter = plot_abundance(ps6,"Genus")
grid.arrange(nrow = 2, plotBefore, plotAfter)
```

Save filtered and pruned dataset
```{r}
saveRDS(ps1, "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps1_3only.rds")
saveRDS(ps3, "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps3_3only.rds")
saveRDS(ps6, "T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps6_3only.rds")
###Clear Environment###
```

Preprocess
```{r}
#Load PS from previous
ps_pre = readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps1_3only.rds")
ps_partial = readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps3_3only.rds")
ps_complete = readRDS("T:/DCEG/CGF/Laboratory/Projects/MR-0084/NP0084-MB5/QC Data/qiime/Combo with NP0084-MB4/04_23_18_input_combo/Output/ps6_3only.rds")

#Review of all steps
qplot(log10(rowSums(otu_table(ps_pre)))) +  xlab("Logged counts-per-sample")
qplot(log10(rowSums(otu_table(ps_partial)))) +  xlab("Logged counts-per-sample")
qplot(rowSums(otu_table(ps_complete))) +  xlab("Logged counts-per-sample")

```

#Input and Evaluation
```{r}
#Determine which input to use
st1 <- ps_partial

#Use weight unifrac to determine outlier samples
st1 <- transform_sample_counts(st1, function(x) log(1 + x)) #already weighted in previous v1
out.wuf.log <- ordinate(st1, method = "MDS", distance = "wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(st1, out.wuf.log, color = "Kit") + labs(col = "Kit") + coord_fixed(sqrt(evals[2] / evals[1]))

#Check on relative abundance levels of the outliers - way above expected values
rel_abund <- t(apply(otu_table(st1), 1, function(x) x / sum(x)))
qplot(rel_abund[, 12], geom = "histogram") + xlab("Relative abundance")
```

Re-Examine Richness, after all filtering
```{r}
#Review diversity (richness)
plot_richness(st1,x="Kit",measures=c("Observed","Shannon"), color="Kit") + theme_bw() + geom_boxplot()

#Plot Side by Side comparisons for top Phylum
plot_bar(st1, x="Kit", fill="Phylum") + facet_wrap(~Type)
plot_bar(st1, x="Type", fill="Phylum") + facet_wrap(~VialID)
```

Evaluate for outliers
```{r}
#Review Bray-Curtis Plot
out.bc.log <- ordinate(st1, method="NMDS", "bray")
evals <- out.bc.log$values$Eigenvalues 
plot_ordination(st1, out.bc.log, color = "Kit", shape = "Type") + geom_text(mapping=aes(label=SampleID))

#Remove outliers and repeat
#st2 <- subset_samples(st1, SampleID != "Sample12" & SampleID !="Sample36")
#out.bc.log <- ordinate(st2, method="NMDS", "bray")
#evals <- out.bc.log$values$Eigenvalues 
#plot_ordination(st2, out.bc.log, color = "Timepoint", shape = "VialID") + geom_text(mapping=aes(label=SampleID))

#If no outliers observed, st1 is the same as st2
st2 <- st1

#Review Double PCOA
out.dpcoa.log <- ordinate(st2, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(st2, out.dpcoa.log, color = "Kit", shape = "Type") + coord_fixed(sqrt(evals[2] / evals[1])) + labs(col = "Kit", shape = "Type")

#Review Weighted Unifrac
out.wuf.log <- ordinate(st2, method = "PCoA", distance ="wunifrac")
plot_ordination(st2, out.dpcoa.log, type = "species", color = "Phylum") +
coord_fixed(sqrt(evals[2] / evals[1]))

#Review PCOA weighted Unifrac - messier version of above
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(st2, out.wuf.log, type = "species", color = "Phylum") +
coord_fixed(sqrt(evals[2] / evals[1]))
```

Ranking
```{r}
abund <- otu_table(st2)
abund_ranks <- t(apply(abund, 1, rank))
abund_ranks <- abund_ranks -40 #Number brings down scale of ranks
abund_ranks[abund_ranks < 1] <-1 #Anything below 1 gets a "tied" score

ranks_pca <- dudi.pca(abund_ranks, scannf = F, nf = 3)
row_scores <- data.frame(li = ranks_pca$li,SampleID = rownames(abund_ranks))
col_scores <- data.frame(co = ranks_pca$co, seq = colnames(abund_ranks))

#Choose Taxa
tax <- tax_table(st2)@.Data %>% data.frame(stringsAsFactors = FALSE)
tax$seq <- rownames(tax)
main_orders <- c("Proteobacteria", "Bacteroidetes", "Firmicutes") #orders to review
tax$Order[!(tax$Order %in% main_orders)] <- "Other"
tax$Order <- factor(tax$Order, levels = c(main_orders, "Other"))
tax$otu_id <- seq_len(ncol(otu_table(st2)))
row_scores <- row_scores %>% left_join(sample_data(st2))
col_scores <- col_scores %>% left_join(tax)

abund_df <- melt(abund, value.name = "abund") %>% left_join(melt(abund_ranks, value.name = "rank"))
colnames(abund_df) <- c("sample", "seq", "abund", "rank")

#Sample a portion of the samples
sample_ix <- sample(1:nrow(abund_df), 9) #of samples to include
ggplot(abund_df %>% filter(sample %in% abund_df$sample[sample_ix])) + geom_point(aes(x = abund, y = rank, col = sample),position = position_jitter(width = 0.2), size = 2) + labs(x = "Abundance", y = "Thresholded rank") + scale_color_brewer(palette = "Set1")
```

Jaccard Dissimilarity Plots
```{r}
net <- make_network(st2, max.dist=.5, distance=function(x){vegan::vegdist(x, "jaccard")})
plot_network(net, st2, color="Kit", line_weight = 0.3, label=NULL)
plot_network(net, st2, color="Type", line_weight = 0.3, label=NULL)
plot_network(net, st2, color="VialID", line_weight = 0.3, label=NULL)
plot_network(net, st2, color="Type", shape="Kit",line_weight = 0.3, label=NULL)
```

Create Phylogeny Trees
```{r}
#Remove decimals from tree for labels
phy_tree(st2)$node.label = substr(phy_tree(st2)$node.label, 1, 4)

#Plot by Phylum
plot_tree(st2,color="Phylum", shape="Kit")
plot_tree(st2,color="Phylum", shape="Type")
plot_tree(st2,color="Phylum", shape="VialID")

#Plot by Class
plot_tree(st2,color="Class", shape="Kit")
plot_tree(st2,color="Class", shape="Type")
plot_tree(st2,color="Class", shape="VialID")

#Plot by Genus
plot_tree(st2,color="Genus", shape="Kit")
plot_tree(st2,color="Genus", shape="Type")
plot_tree(st2,color="Genus", shape="VialID")

#Create spirl plots
plot_tree(st2, color="Kit", ladderize="left") + coord_polar(theta="y")
plot_tree(st2, color="Type", ladderize="left") + coord_polar(theta="y")
plot_tree(st2, color="VialID", ladderize="left") + coord_polar(theta="y")

#Plot by Variables
plot_tree(st2, nodelabf=nodeplotboot(), ladderize="left", color="Kit")
plot_tree(st2, nodelabf=nodeplotboot(), ladderize="left", color="Type")
plot_tree(st2, nodelabf=nodeplotboot(), ladderize="left", color="VialID")
plot_tree(st2, nodelabf=nodeplotboot(), ladderize="left", color="Kit", shape="Type")
```

Create Barplots by Phylum and Class
```{r}
st2 <- prune_taxa(taxa_sums(st2) > 0, st2)

plot_bar(st2,fill="Phylum",x="Kit")
plot_bar(st2,fill="Phylum",x="Type")
plot_bar(st2,fill="Phylum",x="VialID")
plot_bar(st2,fill="Phylum",x="Kit")
plot_bar(st2,fill="Class",x="Type")
plot_bar(st2,fill="Class",x="VialID")
```

RunDESeq2 - Kit
```{r}
head(sample_data(st2)$Kit, 25)
diagdds = phyloseq_to_deseq2(st2, ~ Kit)

# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")

#Results
res = results(diagdds, cooksCutoff = FALSE)
alpha = 1
sigtab = res[which(res$padj < alpha), ]
sigtab = cbind(as(sigtab, "data.frame"), as(tax_table(st2)[rownames(sigtab), ], "matrix"))
head(sigtab)

#Plot Data
theme_set(theme_bw())
scale_fill_discrete <- function(palname = "Set1", ...) {
scale_fill_brewer(palette = palname, ...)
}

# Phylum order
x = tapply(sigtab$log2FoldChange, sigtab$Phylum, function(x) max(x))
x = sort(x, TRUE)
sigtab$Phylum = factor(as.character(sigtab$Phylum), levels=names(x))

# Class order
x = tapply(sigtab$log2FoldChange, sigtab$Class, function(x) max(x))
x = sort(x, TRUE)
sigtab$Class = factor(as.character(sigtab$Class), levels=names(x))

#Plot
ggplot(sigtab, aes(x=Class, y=log2FoldChange, color=Phylum)) + geom_point(size=6) + 
theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust=0.5))
```

RunDESeq2 - Type
```{r}
head(sample_data(st2)$Type, 25)
diagdds = phyloseq_to_deseq2(st2, ~ Type)

# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")

#Results
res = results(diagdds, cooksCutoff = FALSE)
alpha = 1
sigtab = res[which(res$padj < alpha), ]
sigtab = cbind(as(sigtab, "data.frame"), as(tax_table(st2)[rownames(sigtab), ], "matrix"))
head(sigtab)

#Plot Data
theme_set(theme_bw())
scale_fill_discrete <- function(palname = "Set1", ...) { scale_fill_brewer(palette = palname, ...)}

#Phylum order
x = tapply(sigtab$log2FoldChange, sigtab$Phylum, function(x) max(x))
x = sort(x, TRUE)
sigtab$Phylum = factor(as.character(sigtab$Phylum), levels=names(x))

# Genus order
x = tapply(sigtab$log2FoldChange, sigtab$Genus, function(x) max(x))
x = sort(x, TRUE)
sigtab$Genus = factor(as.character(sigtab$Genus), levels=names(x))

#plot
ggplot(sigtab, aes(x=Genus, y=log2FoldChange, color=Phylum)) + geom_point(size=6) + theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust=0.5))
```

Calculate Stats
```{r}
#Save Stats by features
st2_stat_Kit <- plot_richness(st2, measures = c("Shannon", "Simpson", "Chao1"), x="Kit")
st2_stat_VialID <- plot_richness(st2, measures = c("Shannon", "Simpson", "Fisher", "Chao1"), x="VialID") + geom_boxplot()
st2_stat_Diet <- plot_richness(st2, measures = c("Shannon", "Simpson", "Fisher", "Chao1"), x="Diet")

#Plot Data
st2_stat_Kit
st2_stat_VialID
st2_stat_Diet

#Save the Stats Files for each variable
save_Kit <- st2_stat_Kit$data
write.table(save_Kit,"stat_Kit.txt",sep="\t")

save_Type <- st2_stat_Type$data
write.table(save_Type,"save_Type.txt",sep="\t")

save_VialID <- st2_stat_VialID$data
write.table(save_VialID,"save_VialID.txt",sep="\t")

#Read in the tables
st3_stat_Kit <- read.table("stat_Kit.txt", header=TRUE)
st3_stat_Type <- read.table("save_Type.txt", header=TRUE)
st3_stat_VialID <- read.table("save_VialID.txt", header=TRUE)

#Split the data into test types and run test - Shannon
Kit_sh<- st3_stat_Kit[which(st3_stat_Kit$type=='Shannon'),]
Type_sh<- st3_stat_Type[which(st3_stat_Type$type=='Shannon'),]
VialID_sh<- st3_stat_VialID[which(st3_stat_VialID$type=='Shannon'),]

shapiro.test(Kit_sh$value)
aov.shannon.Kit = aov(value ~ Kit, data=Kit_sh)
summary(aov.shannon.Kit)
TukeyHSD(aov.shannon.Kit)

shapiro.test(Type_sh$value)
aov.shannon.Type = aov(value ~ Type, data=Type_sh)
summary(aov.shannon.Type)
TukeyHSD(aov.shannon.Type)

shapiro.test(VialID_sh$value)
aov.shannon.VidalID = aov(value ~ VialID, data=VialID_sh)
summary(aov.shannon.VialID)
TukeyHSD(aov.shannon.VialID)

```